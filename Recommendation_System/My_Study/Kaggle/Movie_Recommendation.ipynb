{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kaggle Netflix - Movie recommendation\n",
    "https://www.kaggle.com/laowingkin/netflix-movie-recommendation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 라이브러리 호출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: surprise in c:\\python39\\lib\\site-packages (0.1)\n",
      "Requirement already satisfied: scikit-surprise in c:\\python39\\lib\\site-packages (from surprise) (1.1.1)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\python39\\lib\\site-packages (from scikit-surprise->surprise) (1.1.0)\n",
      "Requirement already satisfied: numpy>=1.11.2 in c:\\python39\\lib\\site-packages (from scikit-surprise->surprise) (1.21.0)\n",
      "Requirement already satisfied: scipy>=1.0.0 in c:\\python39\\lib\\site-packages (from scikit-surprise->surprise) (1.7.2)\n",
      "Requirement already satisfied: six>=1.10.0 in c:\\python39\\lib\\site-packages (from scikit-surprise->surprise) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "! pip install surprise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import re\n",
    "from scipy.sparse import csr_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from surprise import Reader, Dataset, SVD\n",
    "from surprise.model_selection import cross_validate\n",
    "sns.set_style(\"darkgrid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# csv파일 읽어오기\n",
    "# header = None : read_csv의 header default value는 header = 0이므로 column name이 없으면 0번 행의 값이 \n",
    "# 헤더로 쓰이게 된다. 따라서 header = None으로 header가 없음을 명시해주어야 한다.\n",
    "# names = ['Cust_Id', 'Rating'] : header = None으로 헤더가 없음을 명시했으므로 헤더 자리에 들어갈 column 이름을\n",
    "# 지정해주어야 한다.\n",
    "# use_cols = [0, 1] : 데이터 셋에는 Movie ID, Custormer ID, Rating, Date they gave the ratings column이 있는데,\n",
    "# 여기서 Date를 제외한 'Cust_Id', 'Rating'만 가져와서 각각 이름을 지정해준 것이다.\n",
    "df1 = pd.read_csv(\"../input/combined_data_1.txt\", header = None, names = ['Cust_Id', 'Rating'], usecols = [0, 1])\n",
    "\n",
    "# 'Rating' column의 데이터 형식을 float형식으로 바꿔준다. \n",
    "df1['Rating'] = df1['Rating'].astype('float')\n",
    "\n",
    "print('Dataset 1 shape: {}'.format(df1.shape))\n",
    "print('-Dataset examples-')\n",
    "# 행은 5000000으로 나눠지는 모든 행, 열은 모든 열을 출력한다.\n",
    "# ::a : a로 나누어 떨어지는 번 째에 있는 행들. 물론, 0번째 행도 포함한다.\n",
    "print(df1.iloc[::5000000, :])\n",
    "\n",
    "# 출력 값\n",
    "# Dataset 1 shape: (24058263, 2)\n",
    "# -Dataset examples-\n",
    "#           Cust_Id  Rating\n",
    "# 0              1:     NaN\n",
    "# 5000000   2560324     4.0\n",
    "# 10000000  2271935     2.0\n",
    "# 15000000  1921803     2.0\n",
    "# 20000000  1933327     3.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pandas practice\n",
    "- .iloc[행, 열]\n",
    "- .iloc[a] : a에 해당하는 모든 행\n",
    "- .iloc[a, b] : a와 b에 해당하는 모든 데이터\n",
    "- ex) .iloc[:2, :3] : 0~1행, 0~2열에 해당하는 모든 값들. 즉, 2 by 3 행렬이 선택된다.\n",
    "\n",
    "- groupby('a')['a'].agg(['count']) : a에 대하여 groupby한 뒤 a열의 값을들 count하여 count열에 넣음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     a  b  c   d\n",
      "0  NaN  3  6   9\n",
      "1  1.0  4  7  10\n",
      "2  2.0  5  8  11\n",
      "a    1\n",
      "b    0\n",
      "c    0\n",
      "d    0\n",
      "dtype: int64\n",
      "count    2\n",
      "dtype: int64\n",
      "2.0\n",
      "     a  b  c   d\n",
      "1  1.0  4  7  10\n",
      "2  2.0  5  8  11\n"
     ]
    }
   ],
   "source": [
    "mydict = [{'a': np.nan, 'b': 3, 'c': 6, 'd': 9},\n",
    "          {'a': 1, 'b': 4, 'c': 7, 'd': 10},\n",
    "          {'a': 2, 'b': 5, 'c': 8, 'd': 11}]\n",
    "my_df = pd.DataFrame(mydict)\n",
    "a = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16]\n",
    "\n",
    "c = my_df.groupby('a')['a'].agg(['count'])\n",
    "print(my_df)\n",
    "print(my_df.isnull().sum())\n",
    "print(c.sum())\n",
    "print(my_df.iloc[-1,0])\n",
    "string = '1234569'\n",
    "my_df = my_df[pd.notnull(my_df['a'])]\n",
    "print(my_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combine Dataset\n",
    "- 원래는 총 4개의 csv파일이 있기 때문에 이를 통합해 주어야 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df1\n",
    "# df = df.append(df2)\n",
    "# df = df.append(df3)\n",
    "# df = df.append(df4)\n",
    "\n",
    "# 데이터들을 합쳤으므로, 데이터의 index에 번호를 부여한다.\n",
    "df.index = np.arrange(0, len(df))\n",
    "print('Full dataset shape: {}'.format(df.shape))\n",
    "print('-Dataset examples-')\n",
    "print(df.iloc[::5000000, :])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Viewing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df를 'Rating' 컬럼을 기준으로 groupby 시키면 각 값들(ex. 4.0, 3.5 .etc)에는 여러 Cust_Id가 있을텐데,\n",
    "# 이를 'Rating' 열에 대해 .agg(['count'])를 적용시켜주면 Index가 rating이고 count열이 새로 생겨서 count열의 값은\n",
    "# 각 Rating의 값들을 count한 값이 들어간다.\n",
    "# 위 Pandas practice 참고\n",
    "p = df.groupby('Rating')['Rating'].agg(['count'])\n",
    "\n",
    "# get movie count : df의 결측치를 찾은 뒤 레이팅 값의 결측치의 개수를 movie_count에 넣는다.\n",
    "movie_count = df.isnull().sum()[1]\n",
    "\n",
    "# get customer count : df의 'Cust_Id'열에 unique한 값의 개수에서 결측치의 개수를 뺀다.\n",
    "cust_count = df['Cust_Id'].nunique() - movie_count\n",
    "\n",
    "# get rating count : df의 'Cust_Id'열의 개수에서 결측치의 개수를 뺀다.\n",
    "rating_count = df['Cust_Id'].count() - movie_count\n",
    "\n",
    "# p에 대해 barh그래프를 그리고, legend는 없애고, 그래프 크기는 (15,10)으로 한다.\n",
    "# plot의 barh는 horizontal bar plot으로, 수평적인 막대그래프이다.\n",
    "# legend = False : legend는 범례로, 예를들어 남녀 성별 그래프를 그릴 때 보통 그래프 오른쪽에 있는 그래프 색깔 별 성별을\n",
    "# 나타내는 표시이다.\n",
    "ax = p.plot(kind = 'barh', legend = False, figsize = (15,10))\n",
    "#plt.의 \n",
    "plt.title('Total pool: {:,} Movies, {:,} customers, {:,} ratings given'.format(movie_count, cust_count, rating_count)\n",
    ", fontsize=20)\n",
    "plt.axis('off')\n",
    "\n",
    "# Rating의 값은 1.0, 2.0, 3.0, 4.0, 5.0이 있기 때문에 range(1,6)으로 1부터 5까지 반복해준다.\n",
    "for i in range(1,6):\n",
    "    ax.text(p.iloc[i-1][0]/4, i-1, 'Rating {}: {:.0f}%'.format(i, p.iloc[i-1][0]*100 / p.sum()[0]), \n",
    "    color = 'white', weight = 'bold')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data cleaning\n",
    "Movie ID is really a mess import! Looping through dataframe to add Movie ID column WILL make the Kernel run out of memory as it is too inefficient. I achieve my task by first creating a numpy array with correct length then add the whole array as column into the main dataframe! Let's see how it is done below:\n",
    "\n",
    "Movie ID 열은 매우 복잡하다! Movie ID열을 데이터프레임에 추가하기 위해서 데이터프레임을 반복하는 것은 커널 메모리가 부족해서 매우 비효율적이다. 먼저 데이터프레임에 맞는 NumPy 배열을 만든 뒤 전체 열을 데이터프레임에 column으로 추가하였다.\n",
    "어떻게 했는지 아래에서 확인해보자:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df의 Rating열의 결측치를 확인하는 isnull메서드의 결과 df를 df_nan이란 데이터프레임에 넣는다.\n",
    "df_nan = pd.DataFrame(pd.isnull(df.Rating))\n",
    "# df_nan의 'Rating' 컬럼에서 True인 값들만 df_nan에 넣는다. 이때 df_nan의 모습은 'Rating'열의 값이 True인 행들만 \n",
    "# 모여있다.\n",
    "df_nan = df_nan[df_nan['Rating'] == True]\n",
    "# df_nan의 인덱스를 제거한다.\n",
    "df_nan = df_nan.reset_index()\n",
    "\n",
    "movie_np = []\n",
    "movie_id = 1\n",
    "\n",
    "# 예를 들어 결측치 인덱스가 1, 5, 10이면 2,3,4, 6,7,8,9는 결측치가 아니게되므로 2,3,4에는 np.full((1, 5-1-1),1)인\n",
    "# (1,1,1)을 대입시킨다.\n",
    "for i,j in zip(df_nan['index'][1:],df_nan['index'][:-1]):\n",
    "    # numpy approach\n",
    "    temp = np.full((1,i-j-1), movie_id)\n",
    "    movie_np = np.append(movie_np, temp)\n",
    "    movie_id += 1\n",
    "\n",
    "# Account for last record and corresponding length\n",
    "# numpy approach\n",
    "# 마지막 record에 대해서는 df의 총 길이에서 결측치의 마지막 값을 뺀 뒤에 1을 빼준 값의 길이에 movie_id값으로 이루어진 \n",
    "# np 배열을 넣어주었다.\n",
    "last_record = np.full((1,len(df) - df_nan.iloc[-1, 0] - 1),movie_id)\n",
    "movie_np = np.append(movie_np, last_record)\n",
    "\n",
    "# 출력 값\n",
    "# Movie numpy: [1.000e+00 1.000e+00 1.000e+00 ... 4.499e+03 4.499e+03 4.499e+03]\n",
    "# Length: 24053764\n",
    "# Movie numpy의 배열 형태를 보면 4498개의 결측치가 있나보다.. 라고 생각할 수 있다.\n",
    "\n",
    "\n",
    "# remove those Movie ID rows\n",
    "# df의 'Rating'열의 값이 결측치가 아닌 모든 열을 다시 df에 대입\n",
    "df = df[pd.notnull(df['Rating'])]\n",
    "\n",
    "# df에 'Movie_Id'라는 열을 만들어서 거기에 movie_np를 넣어주는데, 그 전에 movie_np의 값들을 모두 정수형으로 바꾸어서 \n",
    "# 넣어준다\n",
    "df['Movie_Id'] = movie_np.astype(int)\n",
    "# Cust_Id에 대해서도 똑같다.\n",
    "df['Cust_Id'] = df['Cust_Id'].astype(int)\n",
    "print('-Dataset examples-')\n",
    "print(df.iloc[::5000000, :])\n",
    "\n",
    "# 출력 값\n",
    "# -Dataset examples-\n",
    "#           Cust_Id  Rating  Movie_Id\n",
    "# 1         1488844     3.0         1\n",
    "# 5000996    501954     2.0       996\n",
    "# 10001962   404654     5.0      1962\n",
    "# 15002876   886608     2.0      2876\n",
    "# 20003825  1193835     2.0      3825"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data slicing\n",
    "\n",
    "The data set now is super huge. I have tried many different ways but can't get the Kernel running as intended without memory error. Therefore I tried to reduce the data volumn by improving the data quality below:\n",
    "데이터 셋은 매우 크다. 여러 방법을 시도했지만 메모리 에러 없이는 커널을 실행할 수 없었다. 따라서 데이터 품질을 개선해서 데이터의 볼륨을 줄이고자 하였다.\n",
    "\n",
    "- Remove movie with too less reviews (they are relatively not popular)\n",
    "- 리뷰가 너무 적은 영화는 제거하였다(상대적으로 덜 인기있는 영화들).\n",
    "- Remove customer who give too less reviews (they are relatively less active)\n",
    "- 리뷰를 너무 적게 쓴 고객을 지웠다(상대적으로 덜 활동적인 고객들).\n",
    "\n",
    "Having above benchmark will have significant improvement on efficiency, since those unpopular movies and non-active customers still occupy same volumn as those popular movies and active customers in the view of matrix (NaN still occupy space). This should help improve the statistical signifiance too.\n",
    "위의 기준에 따라 개선하였을 때 효율이 크게 증가하였다. 인기가 없는 영화와 비활동적인 고객들은 인기 있는 영화와 활동적인 고객과 행렬의 관점에서는 동일한 비중을 차지하고 있기 때문이었다(여전히 결측치는 존재한다.) 이는 통계적 개선에 큰 도움을 줄 것이다.\n",
    "\n",
    "Let's see how it is implemented:\n",
    "어떻게 작동하는지 알아보자:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = ['count', 'mean']\n",
    "\n",
    "# df를 Movie_Id를 기준으로 중복된 값을 묶은 다음에 'Rating'열에 대해서 count와 mean을 수행을 수행하여 \n",
    "# 각각 count열과 mean열에 넣는다.\n",
    "# df_movie_summary의 열은 count와 mean열만 추가되었을 것임\n",
    "df_movie_summary = df.groupby('Movie_Id')['Rating'].agg(f)\n",
    "# map함수로 df_moive_summary의 index('Movie_Id')를 int형식으로 바꾸어주었음.\n",
    "df_movie_summary.index = df_movie_summary.index.map(int)\n",
    "# 'count'열의 백분위 수로 70%에 있는 값을 소수점 1째자리에서 반올림한다. (혹시 소수점이 있을까봐 지우는 듯함)\n",
    "movie_benchmark = round(df_movie_summary['count'].quantile(0.7),0)\n",
    "# 'count'열의 값이 백분위 수 70%보다 아래에 있는 MovieId는 제외한 나머지 MovieId만 drop_movie_list에 넣는다.\n",
    "# (인덱스 열) => relatively less popular movie..\n",
    "drop_movie_list = df_movie_summary[df_movie_summary['count'] < movie_benchmark].index\n",
    "\n",
    "print('Movie minimum times of review: {}'.format(movie_benchmark))\n",
    "# 출력 결과 : 영화 리뷰 개수의 상위 70%에 해당하는 값이 1799개이다. (생각보다 적네..? 아 많나..? 모르겠다 ㅎㅎ;)\n",
    "# Movie minimum times of review: 1799.0\n",
    "\n",
    "# 이제 customer에 대해 슬라이싱할 차례\n",
    "# df의 'Cust_Id'열에 대해서 중복되는 값을 없앤 뒤 'Rating'에 대해 count와 mean을 계산하여 count, mean 열에 넣는다.\n",
    "# df_cust_summary의 열은 현재 각 Cust_Id별로 계산된 'Rating'의 count값과 mean값이 각각의 열에 들어가있음\n",
    "df_cust_summary = df.groupby('Cust_Id')['Rating'].agg(f)\n",
    "# Movie_Id와 똑같이 Cust_Id를 Int형식으로 바꿔준다.\n",
    "df_cust_summary.index = df_cust_summary.index.map(int)\n",
    "# count개수의 상위 70퍼센트에 해당하는 값을 찾아 소수점 1째 자리에서 반올림해준다.\n",
    "cust_benchmark = round(df_cust_summary['count'].quantile(0.7),0)\n",
    "# 상위 70퍼센트에 해당하는 값보다 적은 리뷰의 개수를 단 고객의 아이디는 삭제한다.(relatively less active customer)\n",
    "drop_cust_list = df_cust_summary[df_cust_summary['count'] < cust_benchmark].index\n",
    "\n",
    "print('Customer minimum times of review: {}'.format(cust_benchmark))\n",
    "# 출력 결과 : 상위 70퍼센트에 해당하는 고객의 리뷰의 개수 : 52개(활동적인 사람 중에서 젤 덜 활동적인..)\n",
    "# 52개는 좀 많은데..?\n",
    "# Customer minimum times of review: 52.0\n",
    "\n",
    "# 기존의 df와 슬라이싱한 df의 volumn차이를 비교하기 위해 .shape메서드로 출력해서 비교해보자.\n",
    "print('Original Shape: {}'.format(df.shape))\n",
    "# ~표시로 df의 'Movie_Id'열의 값이 제거된 리스트에 없는 값들만 df에 넣는다.\n",
    "# ~는 NOT표시\n",
    "df = df[~df['Movie_Id'].isin(drop_movie_list)]\n",
    "# 비인기 영화를 제거한 df에 다시 비활동적인 고객의 리스트에 포함되지 않은 고객들만 넣는다.\n",
    "df = df[~df['Cust_Id'].isin(drop_cust_list)]\n",
    "\n",
    "\n",
    "print('After Trim Shape: {}'.format(df.shape))\n",
    "print('-Data Examples-')\n",
    "print(df.iloc[::5000000, :])\n",
    "\n",
    "# 출력 결과\n",
    "# 기존의 개수는 24053764개로 약 2400만개\n",
    "# 슬라이싱한 이후의 개수는 17337458개로 약 1730만개\n",
    "# df.iloc[::5000000, :]을 출력했음에도 불구하고 -Data Examples-에 696으로 시작하는 이유는 1부터 695번째 까지의 인덱스에\n",
    "# 해당하는 값들은 이미 슬라이싱 되었고 696번째 열이 첫 번째 열이기 때문 \n",
    "# Original Shape: (24053764, 3)\n",
    "# After Trim Shape: (17337458, 3)\n",
    "# -Data Examples-\n",
    "#           Cust_Id  Rating  Movie_Id\n",
    "# 696        712664     5.0         3\n",
    "# 6932490   1299309     5.0      1384\n",
    "# 13860273   400155     3.0      2660\n",
    "# 20766530   466962     4.0      3923\n",
    "\n",
    "# Let's pivot the data set and put it into a giant matrix - we need it for our recommendation system:\n",
    "# 데이터 셋을 pivot하여 큰 메트릭스에 넣자! - 추천시스템을 구현하기 위해 필요하다.\n",
    "# pivot의 의미 : 데이터 테이블을 재배치한다는 의미\n",
    "# ex) df1.pivot(index = None, columns = None, values = None)\n",
    "# index : index로 사용될 column\n",
    "# columns = column으로 사용될 column\n",
    "# values = value에 채우고자 하는 column\n",
    "\n",
    "# df에 대하여 value값에는 'Rating'열을 채우고, 인덱스는 고객의 아이디, column에는 Movie_Id를 넣어준다.\n",
    "#         Movie_Id ~ ~ ~\n",
    "# Cust_Id   3.0     3.0 \n",
    "#    .      4.0     1.0\n",
    "#    .      3.0     5.0\n",
    "#    .\n",
    "# 위와 같은 형식으로 피벗테이블을 만들어준다.\n",
    "df_p = pd.pivot_table(df,values='Rating',index='Cust_Id',columns='Movie_Id')\n",
    "\n",
    "print(df_p.shape)\n",
    "# 출력 결과 : 143458개의 Cust_Id, 1350개의 Movie_Id가 있음\n",
    "# (143458, 1350)\n",
    "\n",
    "# --------------------------------------------------------------------------------------------\n",
    "# Kaggle에서 알려준 데이터프레임을 나누는 다른 방법, 더 나은 방법은 아니라고 함.\n",
    "# Below is another way I used to sparse the dataframe...doesn't seem to work better\n",
    "\n",
    "# df의 'Cust_Id'중에 unique한 값들만 가져와서 정렬한다음에 리스트로 만들어 Cust_Id_u에 넣는다.\n",
    "Cust_Id_u = list(sorted(df['Cust_Id'].unique()))\n",
    "# df의 'Movie_Id'중에 unique한 값들만 가져와서 정렬한다음에 리스트로 만들어 Movie_Id_u에 넣는다.\n",
    "Movie_Id_u = list(sorted(df['Movie_Id'].unique()))\n",
    "# df의 'Rating'열에 해당하는 값들을 리스트로 만들어 data에 넣는다.\n",
    "data = df['Rating'].tolist()\n",
    "# df의 'Cust_Id'열의 값을 category형식으로 바꾼 다음 categories에 넣어준 Cust_Id_u에 따라 \n",
    "# .cat.codes로 임의의 숫자형으로 변경하여 row에 넣어준다.\n",
    "row = df['Cust_Id'].astype('category', categories=Cust_Id_u).cat.codes\n",
    "# 위와 동일\n",
    "col = df['Movie_Id'].astype('category', categories=Movie_Id_u).cat.codes\n",
    "\n",
    "# Cust_Id_u by Movie_Id_u sparse_matrix(희소행렬: 비교적 0이 많은 행렬)를 만들어준다.\n",
    "sparse_matrix = csr_matrix((data, (row, col)), shape=(len(Cust_Id_u), len(Movie_Id_u)))\n",
    "# why convert the sparse matrix to dense matrix ?\n",
    "df_p = pd.DataFrame(sparse_matrix.todense(), index=Cust_Id_u, columns=Movie_Id_u)\n",
    "# 0을 결측치로 바꿔준다.\n",
    "df_p = df_p.replace(0, np.NaN)\n",
    "# --------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data mapping\n",
    "Now we load the movie mapping file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# csv파일을 읽어온 뒤 column 이름을 'Movie_Id', 'Year', 'Name'으로 가져온다.\n",
    "df_title = pd.read_csv('../input/movie_titles.csv', encoding = \"ISO-8859-1\", \n",
    "header = None, names = ['Movie_Id', 'Year', 'Name'])\n",
    "\n",
    "# index는 'Movie_Id'로 설정한다.\n",
    "# inplace = True를 넣어주면 df_title = df_title.set_index('Movie_Id')처럼 다시 넣어줄 필요 없이 제자리에서\n",
    "# 수정해준다. 와 이거 혁명이다.\n",
    "df_title.set_index('Movie_Id', inplace = True)\n",
    "print (df_title.head(10))\n",
    "# 출력 값\n",
    "#             Year                          Name\n",
    "# Movie_Id                                      \n",
    "# 1         2003.0               Dinosaur Planet\n",
    "# 2         2004.0    Isle of Man TT 2004 Review\n",
    "# 3         1997.0                     Character\n",
    "# 4         1994.0  Paula Abdul's Get Up & Dance\n",
    "# 5         2004.0      The Rise and Fall of ECW\n",
    "# 6         1997.0                          Sick\n",
    "# 7         1992.0                         8 Man\n",
    "# 8         2004.0    What the #$*! Do We Know!?\n",
    "# 9         1991.0      Class of Nuke 'Em High 2\n",
    "# 10        2001.0                       Fighter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recommendation models\n",
    "Well all data required is loaded and cleaned! Next let's get into the recommendation system."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recommend with Collaborative Filtering\n",
    "Evalute performance of collaborative filtering, with just first 100K rows for faster process:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "아직 CF에 대해 공부를 덜 했습니다..!"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "63fd5069d213b44bf678585dea6b12cceca9941eaf7f819626cde1f2670de90d"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
