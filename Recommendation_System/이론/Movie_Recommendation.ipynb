{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kaggle Netflix - Movie recommendation\n",
    "https://www.kaggle.com/laowingkin/netflix-movie-recommendation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 라이브러리 호출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: surprise in c:\\python39\\lib\\site-packages (0.1)\n",
      "Requirement already satisfied: scikit-surprise in c:\\python39\\lib\\site-packages (from surprise) (1.1.1)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\python39\\lib\\site-packages (from scikit-surprise->surprise) (1.1.0)\n",
      "Requirement already satisfied: numpy>=1.11.2 in c:\\python39\\lib\\site-packages (from scikit-surprise->surprise) (1.21.0)\n",
      "Requirement already satisfied: scipy>=1.0.0 in c:\\python39\\lib\\site-packages (from scikit-surprise->surprise) (1.7.2)\n",
      "Requirement already satisfied: six>=1.10.0 in c:\\python39\\lib\\site-packages (from scikit-surprise->surprise) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "! pip install surprise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import re\n",
    "from scipy.sparse import csr_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from surprise import Reader, Dataset, SVD\n",
    "from surprise.model_selection import cross_validate\n",
    "sns.set_style(\"darkgrid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# csv파일 읽어오기\n",
    "# header = None : read_csv의 header default value는 header = 0이므로 column name이 없으면 0번 행의 값이 \n",
    "# 헤더로 쓰이게 된다. 따라서 header = None으로 header가 없음을 명시해주어야 한다.\n",
    "# names = ['Cust_Id', 'Rating'] : header = None으로 헤더가 없음을 명시했으므로 헤더 자리에 들어갈 column 이름을\n",
    "# 지정해주어야 한다.\n",
    "# use_cols = [0, 1] : 데이터 셋에는 Movie ID, Custormer ID, Rating, Date they gave the ratings column이 있는데,\n",
    "# 여기서 Date를 제외한 'Cust_Id', 'Rating'만 가져와서 각각 이름을 지정해준 것이다.\n",
    "df1 = pd.read_csv(\"../input/combined_data_1.txt\", header = None, names = ['Cust_Id', 'Rating'], usecols = [0, 1])\n",
    "\n",
    "# 'Rating' column의 데이터 형식을 float형식으로 바꿔준다. \n",
    "df1['Rating'] = df1['Rating'].astype('float')\n",
    "\n",
    "print('Dataset 1 shape: {}'.format(df1.shape))\n",
    "print('-Dataset examples-')\n",
    "# 행은 5000000으로 나눠지는 모든 행, 열은 모든 열을 출력한다.\n",
    "# ::a : a로 나누어 떨어지는 번 째에 있는 행들. 물론, 0번째 행도 포함한다.\n",
    "print(df1.iloc[::5000000, :])\n",
    "\n",
    "# 출력 값\n",
    "# Dataset 1 shape: (24058263, 2)\n",
    "# -Dataset examples-\n",
    "#           Cust_Id  Rating\n",
    "# 0              1:     NaN\n",
    "# 5000000   2560324     4.0\n",
    "# 10000000  2271935     2.0\n",
    "# 15000000  1921803     2.0\n",
    "# 20000000  1933327     3.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pandas practice\n",
    "- .iloc[행, 열]\n",
    "- .iloc[a] : a에 해당하는 모든 행\n",
    "- .iloc[a, b] : a와 b에 해당하는 모든 데이터\n",
    "- ex) .iloc[:2, :3] : 0~1행, 0~2열에 해당하는 모든 값들. 즉, 2 by 3 행렬이 선택된다.\n",
    "\n",
    "- groupby('a')['a'].agg(['count']) : a에 대하여 groupby한 뒤 a열의 값을들 count하여 count열에 넣음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     a  b  c   d\n",
      "0  NaN  3  6   9\n",
      "1  1.0  4  7  10\n",
      "2  2.0  5  8  11\n",
      "a    1\n",
      "b    0\n",
      "c    0\n",
      "d    0\n",
      "dtype: int64\n",
      "count    2\n",
      "dtype: int64\n",
      "2.0\n",
      "     a  b  c   d\n",
      "1  1.0  4  7  10\n",
      "2  2.0  5  8  11\n"
     ]
    }
   ],
   "source": [
    "mydict = [{'a': np.nan, 'b': 3, 'c': 6, 'd': 9},\n",
    "          {'a': 1, 'b': 4, 'c': 7, 'd': 10},\n",
    "          {'a': 2, 'b': 5, 'c': 8, 'd': 11}]\n",
    "my_df = pd.DataFrame(mydict)\n",
    "a = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16]\n",
    "\n",
    "c = my_df.groupby('a')['a'].agg(['count'])\n",
    "print(my_df)\n",
    "print(my_df.isnull().sum())\n",
    "print(c.sum())\n",
    "print(my_df.iloc[-1,0])\n",
    "string = '1234569'\n",
    "my_df = my_df[pd.notnull(my_df['a'])]\n",
    "print(my_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combine Dataset\n",
    "- 원래는 총 4개의 csv파일이 있기 때문에 이를 통합해 주어야 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df1\n",
    "# df = df.append(df2)\n",
    "# df = df.append(df3)\n",
    "# df = df.append(df4)\n",
    "\n",
    "# 데이터들을 합쳤으므로, 데이터의 index에 번호를 부여한다.\n",
    "df.index = np.arrange(0, len(df))\n",
    "print('Full dataset shape: {}'.format(df.shape))\n",
    "print('-Dataset examples-')\n",
    "print(df.iloc[::5000000, :])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Viewing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df를 'Rating' 컬럼을 기준으로 groupby 시키면 각 값들(ex. 4.0, 3.5 .etc)에는 여러 Cust_Id가 있을텐데,\n",
    "# 이를 'Rating' 열에 대해 .agg(['count'])를 적용시켜주면 Index가 rating이고 count열이 새로 생겨서 count열의 값은\n",
    "# 각 Rating의 값들을 count한 값이 들어간다.\n",
    "# 위 Pandas practice 참고\n",
    "p = df.groupby('Rating')['Rating'].agg(['count'])\n",
    "\n",
    "# get movie count : df의 결측치를 찾은 뒤 레이팅 값의 결측치의 개수를 movie_count에 넣는다.\n",
    "movie_count = df.isnull().sum()[1]\n",
    "\n",
    "# get customer count : df의 'Cust_Id'열에 unique한 값의 개수에서 결측치의 개수를 뺀다.\n",
    "cust_count = df['Cust_Id'].nunique() - movie_count\n",
    "\n",
    "# get rating count : df의 'Cust_Id'열의 개수에서 결측치의 개수를 뺀다.\n",
    "rating_count = df['Cust_Id'].count() - movie_count\n",
    "\n",
    "# p에 대해 barh그래프를 그리고, legend는 없애고, 그래프 크기는 (15,10)으로 한다.\n",
    "# plot의 barh는 horizontal bar plot으로, 수평적인 막대그래프이다.\n",
    "# legend = False : legend는 범례로, 예를들어 남녀 성별 그래프를 그릴 때 보통 그래프 오른쪽에 있는 그래프 색깔 별 성별을\n",
    "# 나타내는 표시이다.\n",
    "ax = p.plot(kind = 'barh', legend = False, figsize = (15,10))\n",
    "#plt.의 \n",
    "plt.title('Total pool: {:,} Movies, {:,} customers, {:,} ratings given'.format(movie_count, cust_count, rating_count)\n",
    ", fontsize=20)\n",
    "plt.axis('off')\n",
    "\n",
    "# Rating의 값은 1.0, 2.0, 3.0, 4.0, 5.0이 있기 때문에 range(1,6)으로 1부터 5까지 반복해준다.\n",
    "for i in range(1,6):\n",
    "    ax.text(p.iloc[i-1][0]/4, i-1, 'Rating {}: {:.0f}%'.format(i, p.iloc[i-1][0]*100 / p.sum()[0]), \n",
    "    color = 'white', weight = 'bold')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data cleaning\n",
    "Movie ID is really a mess import! Looping through dataframe to add Movie ID column WILL make the Kernel run out of memory as it is too inefficient. I achieve my task by first creating a numpy array with correct length then add the whole array as column into the main dataframe! Let's see how it is done below:\n",
    "\n",
    "Movie ID 열은 매우 복잡하다! Movie ID열을 데이터프레임에 추가하기 위해서 데이터프레임을 반복하는 것은 커널 메모리가 부족해서 매우 비효율적이다. 먼저 데이터프레임에 맞는 NumPy 배열을 만든 뒤 전체 열을 데이터프레임에 column으로 추가하였다.\n",
    "어떻게 했는지 아래에서 확인해보자:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df의 Rating열의 결측치를 확인하는 isnull메서드의 결과 df를 df_nan이란 데이터프레임에 넣는다.\n",
    "df_nan = pd.DataFrame(pd.isnull(df.Rating))\n",
    "# df_nan의 'Rating' 컬럼에서 True인 값들만 df_nan에 넣는다. 이때 df_nan의 모습은 'Rating'열의 값이 True인 행들만 \n",
    "# 모여있다.\n",
    "df_nan = df_nan[df_nan['Rating'] == True]\n",
    "# df_nan의 인덱스를 제거한다.\n",
    "df_nan = df_nan.reset_index()\n",
    "\n",
    "movie_np = []\n",
    "movie_id = 1\n",
    "\n",
    "# 예를 들어 결측치 인덱스가 1, 5, 10이면 2,3,4, 6,7,8,9는 결측치가 아니게되므로 2,3,4에는 np.full((1, 5-1-1),1)인\n",
    "# (1,1,1)을 대입시킨다.\n",
    "for i,j in zip(df_nan['index'][1:],df_nan['index'][:-1]):\n",
    "    # numpy approach\n",
    "    temp = np.full((1,i-j-1), movie_id)\n",
    "    movie_np = np.append(movie_np, temp)\n",
    "    movie_id += 1\n",
    "\n",
    "# Account for last record and corresponding length\n",
    "# numpy approach\n",
    "# 마지막 record에 대해서는 df의 총 길이에서 결측치의 마지막 값을 뺀 뒤에 1을 빼준 값의 길이에 movie_id값으로 이루어진 \n",
    "# np 배열을 넣어주었다.\n",
    "last_record = np.full((1,len(df) - df_nan.iloc[-1, 0] - 1),movie_id)\n",
    "movie_np = np.append(movie_np, last_record)\n",
    "\n",
    "# 출력 값\n",
    "# Movie numpy: [1.000e+00 1.000e+00 1.000e+00 ... 4.499e+03 4.499e+03 4.499e+03]\n",
    "# Length: 24053764\n",
    "# Movie numpy의 배열 형태를 보면 4498개의 결측치가 있나보다.. 라고 생각할 수 있다.\n",
    "\n",
    "\n",
    "# remove those Movie ID rows\n",
    "# df의 'Rating'열의 값이 결측치가 아닌 모든 열을 다시 df에 대입\n",
    "df = df[pd.notnull(df['Rating'])]\n",
    "\n",
    "# df에 'Movie_Id'라는 열을 만들어서 거기에 movie_np를 넣어주는데, 그 전에 movie_np의 값들을 모두 정수형으로 바꾸어서 \n",
    "# 넣어준다\n",
    "df['Movie_Id'] = movie_np.astype(int)\n",
    "# Cust_Id에 대해서도 똑같다.\n",
    "df['Cust_Id'] = df['Cust_Id'].astype(int)\n",
    "print('-Dataset examples-')\n",
    "print(df.iloc[::5000000, :])\n",
    "\n",
    "# 출력 값\n",
    "# -Dataset examples-\n",
    "#           Cust_Id  Rating  Movie_Id\n",
    "# 1         1488844     3.0         1\n",
    "# 5000996    501954     2.0       996\n",
    "# 10001962   404654     5.0      1962\n",
    "# 15002876   886608     2.0      2876\n",
    "# 20003825  1193835     2.0      3825"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data slicing\n",
    "\n",
    "The data set now is super huge. I have tried many different ways but can't get the Kernel running as intended without memory error. Therefore I tried to reduce the data volumn by improving the data quality below:\n",
    "데이터 셋은 매우 크다. 여러 방법을 시도했지만 메모리 에러 없이는 커널을 실행할 수 없었다. 따라서 데이터 품질을 개선해서 데이터의 볼륨을 줄이고자 하였다.\n",
    "\n",
    "- Remove movie with too less reviews (they are relatively not popular)\n",
    "- 리뷰가 너무 적은 영화는 제거하였다(상대적으로 덜 인기있는 영화들).\n",
    "- Remove customer who give too less reviews (they are relatively less active)\n",
    "- 리뷰를 너무 적게 쓴 고객을 지웠다(상대적으로 덜 활동적인 고객들).\n",
    "\n",
    "Having above benchmark will have significant improvement on efficiency, since those unpopular movies and non-active customers still occupy same volumn as those popular movies and active customers in the view of matrix (NaN still occupy space). This should help improve the statistical signifiance too.\n",
    "위의 기준에 따라 개선하였을 때 효율이 크게 증가하였다. 인기가 없는 영화와 비활동적인 고객들은 인기 있는 영화와 활동적인 고객과 행렬의 관점에서는 동일한 비중을 차지하고 있기 때문이었다(여전이 결측치는 존재한다.) 이는 통계적 개선에 큰 도움을 줄 것이다.\n",
    "\n",
    "Let's see how it is implemented:\n",
    "어떻게 작동하는지 알아보자:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "63fd5069d213b44bf678585dea6b12cceca9941eaf7f819626cde1f2670de90d"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
